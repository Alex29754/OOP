from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
from nltk.corpus import stopwords
import string

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤
nltk.download('stopwords')
stop_words = stopwords.words('russian') + stopwords.words('english')  # –ú–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å —è–∑—ã–∫


# === –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ ===
def extract_keywords(text, top_n=10):
    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
    text = text.lower().translate(str.maketrans('', '', string.punctuation))

    # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è TF-IDF
    vectorizer = TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 2))  # 1- –∏ 2-–≥—Ä–∞–º–º—ã
    tfidf_matrix = vectorizer.fit_transform([text])

    # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–∞ –∏ –∏—Ö –≤–µ—Å–∞
    feature_array = vectorizer.get_feature_names_out()
    tfidf_scores = tfidf_matrix.toarray()[0]

    # –°–æ–µ–¥–∏–Ω—è–µ–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    word_score_pairs = list(zip(feature_array, tfidf_scores))
    sorted_keywords = sorted(word_score_pairs, key=lambda x: x[1], reverse=True)

    # –í—ã–≤–æ–¥
    print("üîë –¢–æ–ø –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏ —Ñ—Ä–∞–∑:")
    for word, score in sorted_keywords[:top_n]:
        print(f"{word:<25} ‚Äî –≤–µ—Å: {score:.4f}")


# === –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ===
if __name__ == "__main__":
    text_input = input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç: ")
    extract_keywords(text_input, top_n=10)
